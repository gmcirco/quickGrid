% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gbm_fit.R
\docType{data}
\name{param}
\alias{param}
\title{Fit a gradient boosted tree model}
\format{
An object of class \code{list} of length 6.
}
\usage{
param
}
\arguments{
\item{prep_data}{Model list output from 'prep_data' function.}

\item{model_params}{Optional \code{xgboost} model parameters. Defaults to NULL.}

\item{eta}{Step size shrinkage (aka 'learning rate). Lower values imply smaller steps and higher shrinkage.}

\item{gamma}{Minimum loss required to make a partition on a leaf node. Larger values imply more conservative models}

\item{max_depth}{Maximum tree depth. Higher values imply more complex trees, but also more overfitting.}

\item{min_child_weight}{Minimum weight required for a leaf node. Higher values imply more conservative trees.}

\item{subsample}{Ratio of observations to randomly sub sample each boosting iteration. Lower values tend to help prevent overfitting.}

\item{plot_importance}{Should variable importance values be plotted? Defaults to TRUE.}

\item{cv}{Should model parameters be chosen using cross validation? Defaults to FALSE.}

\item{cv.eta}{Step size shrinkage (aka 'learning rate). Lower values imply smaller steps and higher shrinkage.}

\item{cv.gamma}{Minimum loss required to make a partition on a leaf node. Larger values imply more conservative models}

\item{cv.max_depth}{Maximum tree depth. Higher values imply more complex trees, but also more overfitting.}

\item{cv.min_child_weight}{Minimum weight required for a leaf node. Higher values imply more conservative trees.}

\item{cv.subsample}{Ratio of observations to randomly sub sample each boosting iteration. Lower values tend to help prevent overfitting.}

\item{cv.nrounds}{Maximum number of boosting rounds. More rounds are needed for lower values of eta.}
}
\description{
This is essentially a wrapper around the existing \code{xgboost} function. This function provides a number of conveniences to speed up model building,
including some help selecting reasonable parameters, evaluating fit, and examining variable importance.
Users should provide data prepared using the 'prep_data' function.
By default, \code{gbm_fit} attempts to fit a reasonable model using built-in parameters, or using cross-validation (preferred!).
Users are STRONGLY encouraged to tune the model parameters using some estimate of out-of-sample prediction.
The built-in cross-validation step greatly aids this step by testing a range of values in a tuning grid,
finding the model that minimizes the loss function, then fitting using the chosen parameters.
}
\keyword{datasets}
